---
title: "Lung Data"
output: html_document
date: '2022-04-26'
---

```{r,echo=FALSE, results='hide', message=FALSE, warning=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("metagenomeSeq")
BiocManager::install("biomformat")
```

## Introduction
This vignette demonstrates various aspects of an association study pipeline. See the complete list below. The package includes the following functions: help(package=metagenomeSeq). To learn more about a particular function, call = ?function. Check out our new fitFeatureModel function.
```{r, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
library(metagenomeSeq)
```

## Data preparation
### Biom-format
The loadBiom function loads into BIOM files the output from many commonly used programs and functions. A gateway is provided by biom2MRexperiment and MRexperiment2biom as a bridge between objects defined in the biom package and experiment objects defined in MRexperiment object. The biomformat package makes it possible to read and write files in the Biom format.
```{r, echo=TRUE, results='markup'}
# reading in a biom file
library(biomformat)
biom_file <- system.file("extdata", "min_sparse_otu_table.biom",
package = "biomformat")
b <- read_biom(biom_file)
biom2MRexperiment(b)
```
Here is an example writing out the mouseData MRexperiment object to a BIOM file.
```{r, echo=TRUE, results='markup'}
data(mouseData)
# options include to normalize or not
b <- MRexperiment2biom(mouseData)
write_biom(b, biom_file = "/Users/sravanisaadhu/Desktop/otu_table.biom")
```

### Loading count data
MetagenomeSeq provides a portion of the lung microbiome's OTU matrix in the "extdata" folder of the library. Tab-delimited files are used to store OTU matrix data. The Meta script loads these files. Counts and taxa are listed.
```{r, echo=TRUE, results='markup'}
dataDirectory <- system.file("extdata", package = "metagenomeSeq")
lung = loadMeta(file.path(dataDirectory, "CHK_NAME.otus.count.csv"))
dim(lung$counts)
```

### Loading taxonomy
The annotated taxonomy should now be loaded. Ensure that your annotations have been added to the taxonomy. and OTUs are in the same order as your matrix rows.
```{r, echo=TRUE, results='markup'}
taxa = read.delim(file.path(dataDirectory, "CHK_otus.taxonomy.csv"),
stringsAsFactors = FALSE)
```
### Loading metadata
With the help of loadPhenoData Phenotype data can be easily loaded and data will be loaded as a list.
```{r, echo=TRUE, results='markup'}
clin = loadPhenoData(file.path(dataDirectory, "CHK_clinical.csv"),
tran = TRUE)
ord = match(colnames(lung$counts), rownames(clin))
clin = clin[ord, ]
head(clin[1:2, ])
```
### Creating a MRexperiment object
The newMRexperiment function includes count matrices, phenoData (annotated data frames), and FeatureData as input (annotated data frame). Biobase provides the ability to create annotations Data frame. Library size (depth of coverage) and normalization factor are also optional input.
```{r, echo=TRUE, results='markup'}
phenotypeData = AnnotatedDataFrame(clin)
phenotypeData
```
Featured data frame. In this example, this is just an OTU number, but it can also be an annotated multi-level classification.
```{r, echo=TRUE, results='markup'}
OTUdata = AnnotatedDataFrame(taxa)
OTUdata
obj = newMRexperiment(lung$counts,phenoData=phenotypeData,featureData=OTUdata)
obj
```
### Example datasets
Human Lung Microbiome : Lung microbiome consists of samples of respiratory flora from 6 healthy people. 3 healthy non-smokers and 3 healthy smokers or The  upper respiratory tract was collected by mouthwash and oral / nasopharyngeal swabs.
Notobiotic intestine of humanized mice : Treated 12 sterile C57BL / 6J adult male  mice eat a low-fat, plant-based, polysaccharide-rich diet. Each mouse was gavage to a healthy adult Human fecal substance.
```{r, echo=TRUE, results='markup'}
data(lungData)
lungData
data(mouseData)
mouseData
```

### Useful commands
Phenotype information can be accessed with the phenoData and pData methods:
```{r, echo=TRUE, results='markup'}
phenoData(obj)
head(pData(obj), 3)
```
Feature information can be accessed with the featureData and fData methods:
```{r, echo=TRUE, results='markup'}
featureData(obj)
head(fData(obj)[, -c(2, 10)], 3)
head(MRcounts(obj[, 1:2]))
featuresToKeep = which(rowSums(obj) >= 100)
samplesToKeep = which(pData(obj)$SmokingStatus == "Smoker")
obj_smokers = obj[featuresToKeep, samplesToKeep]
obj_smokers
head(pData(obj_smokers), 3)
```
Alternative normalization scaling factors can be accessed or replaced with the normFactors
method:
```{r, echo=TRUE, results='markup'}
head(normFactors(obj))
normFactors(obj) <- rnorm(ncol(obj))
head(normFactors(obj))
```
Library sizes (sequencing depths) can be accessed or replaced with the libSize method:
```{r, echo=TRUE, results='markup'}
head(libSize(obj))
libSize(obj) <- rnorm(ncol(obj))
head(libSize(obj))
```
Additionally, data can be filtered to maintain a threshold of minimum depth or OTU presence:
```{r, echo=TRUE, results='markup'}
data(mouseData)
filterData(mouseData, present = 10, depth = 1000)
```
Two MRexperiment-class objects can be merged with the mergeMRexperiments function, e.g.:
```{r, echo=TRUE, results='markup'}
data(mouseData)
newobj = mergeMRexperiments(mouseData, mouseData)
newobj
```

##  Normalization
Normalization is required because the depth of coverage varies between samples. cumNorm is Normalization method that calculates the scaling factor corresponding to the sum of the counts up to the specified value Quantile. 
 These normalization factors are stored in the experiment summary slot. A function to determine the correct percentile cumNormStat, an exportMat to store a normalized count, or a function to store various things Sample stats exportStats are also provided. Easy access to normalized counts  cumNormMat (MRexperimentObject) or MRcounts (MRexperimentObject, norm = TRUE, log = FALSE)

### Calculating normalization factors
After defining the MRexperiment object, the first step is to calculate the correct percentile  Normalization is important. There are several ways to calculate and visualize relative values 
Difference in  reference.
```{r, echo=TRUE, results='markup'}
data(lungData)
p = cumNormStatFast(lungData)
lungData = cumNorm(lungData, p = p)
```
#### Calculating normalization factors using Wrench
Instead of normalizing the count with cumNorm, you can also use keyNorm. Works the same However, cumNorm  takes an argument condition instead of p. Condition is a factor Use a value that divides the sample into the target phenotype groups.
```{r, echo=TRUE, results='markup', warning=FALSE}
condition = mouseData$diet
mouseData = wrenchNorm(mouseData, condition = condition)
```
### Exporting data
Normalized count matrices can be exported as:
```{r, echo=TRUE, results='markup'}
mat = MRcounts(lungData, norm = TRUE, log = TRUE)[1:5, 1:5]
exportMat(mat, file = file.path(dataDirectory, "tmp.tsv"))
exportStats(lungData[, 1:5], file = file.path(dataDirectory,
"tmp.tsv"))
head(read.csv(file = file.path(dataDirectory, "tmp.tsv"), sep = "\t"))
```
## Statistical testing
Now that we've processed the normalization, we can see the effect of undersampling. Recognize different frequency characteristics (OTU, genes, etc.). This is our latest development, We also recommend fitFeatureModel instead of fitZig. MRcoefs, MRtable, MRfulltable are convenient. A summary table of  model output.
###  fitFeatureModel for differential abundance testing
Here is an example comparing smokerâ€™s and non-smokers lung microbiome.
```{r, echo=TRUE, results='markup'}
data(lungData)
lungData = lungData[, -which(is.na(pData(lungData)$SmokingStatus))]
lungData = filterData(lungData, present = 30, depth = 1)
lungData <- cumNorm(lungData, p = 0.5)
pd <- pData(lungData)
mod <- model.matrix(~1 + SmokingStatus, data = pd)
lungres1 = fitFeatureModel(lungData, mod)
head(MRcoefs(lungres1))
```

### Zero-inflated Gaussian mixture model
The depth of coverage of a sample is directly related to the number of features found in the sample. A sample that motivates a zero-expansion Gauss (ZIG) mixed model. Below figure shows A linear relationship between the depth of coverage and the OTU identification. It is ubiquitous in the currently available marker gene research datasets. For an overview of  mathematical models, see. 
The fitZig function runs a complex mathematical optimization routine to estimate the probability that  a particular feature null in the sample is  technical null. function It relies heavily on the limma package. Design matrices can be created in R using. It is a model.matrix function and is an input to fitZig.

#### Example using fitZig for differential abundance testing
It's recommended that to remove the feature based on the estimated number of valid samples. See Calculate valid samples. It is recommended to remove less than features The average number of valid samples for all properties. If you basically use it, set eff = 0.5 MRcoefs, MRfulltable or MRtable. Use a function to find  a feature that is not in the group uniqueFeatures provides a table of  feature IDs, number of positive features, and reads for each group.
```{r, echo=TRUE, results='markup'}
data(lungData)
controls = grep("Extraction.Control", pData(lungData)$SampleType)
lungTrim = lungData[, -controls]
rareFeatures = which(rowSums(MRcounts(lungTrim) > 0) < 10)
lungTrim = lungTrim[-rareFeatures, ]
lungp = cumNormStat(lungTrim, pFlag = TRUE, main = "Trimmed lung data")
lungTrim = cumNorm(lungTrim, p = lungp)
```

After the user has defined the appropriate model matrix for the hypothesis test, there is an optional model matrix Input to fitZig, including the settings set by zigControl. Ask the user for confirmation help files for  fitZig and zigControl. In this example, we include the body position as follows: 
We would like to test for  bacteria that are covariates and have different abundances for smokers and nonsmokers.
```{r, echo=TRUE, results='markup'}
smokingStatus = pData(lungTrim)$SmokingStatus
bodySite = pData(lungTrim)$SampleType
normFactor = normFactors(lungTrim)
normFactor = log2(normFactor/median(normFactor) + 1)
mod = model.matrix(~smokingStatus + bodySite + normFactor)
settings = zigControl(maxit = 10, verbose = TRUE)
fit = fitZig(obj = lungTrim, mod = mod, useCSSoffset = FALSE,
control = settings)
```

#### Multiple groups
Assuming you have multiple groups, you can take advantage of Limma's topTable feature. For F-test and contrast functions to compare covariates with multiple groups  of interest or the fitZig output contains an MLArrayLMLimma object that can be called  by other functions. If fitZig runs by default, additional covariates are added to the design matrix or Fit and  ultimate design matrix are very important for contrast.
```{r, echo=TRUE, results='markup'}
settings = zigControl(maxit = 1, verbose = FALSE)
mod = model.matrix(~bodySite)
colnames(mod) = levels(bodySite)
res = fitZig(obj = lungTrim, mod = mod, control = settings)
zigFit = slot(res, "fit")
finalMod = slot(res, "fit")$design
contrast.matrix = makeContrasts(BAL.A - BAL.B, OW - PSB, levels = finalMod)
fit2 = contrasts.fit(zigFit, contrast.matrix)
fit2 = eBayes(fit2)
topTable(fit2)
```

#### Exporting fits
Currently, functions are being developed to package and output the results cleaner, but MRcoefs, 
You can use MRtable, MRfulltable  to view and export coefficient fits and related statistics. 
See the data help file, which contains the optional output values, to see the difference. Important clues the by variable controls which coefficients are of interest, and the coef determines them advertisement.

```{r, echo=TRUE, results='markup'}
taxa = sapply(strsplit(as.character(fData(lungTrim)$taxa), split = ";"),
function(i) {
i[length(i)]
})
head(MRcoefs(fit, taxa = taxa, coef = 2))
```

### Time series analysis
The method for calculating the time interval is implemented in the fitTimeSeries function Which bacteria occur at different frequencies? Fitting is performed using the smoothing spline ANOVA 20 (SSANOVA) Implemented in the gss package. Observations made at multiple time points For two groups, this method computes a function that models all frequency differences time. Using the order of group membership, It is an indifference curve of  the time interval of interest and indicates an important time interval.

### Log Normal permutation test
Contains a standard lognormal linear model with permutation-based pvalues permutations. Shows the fitting of the same model as above, using a sequence of 10 that provides the resolution of the p-value. To 1/10. The coef parameter refers to the coefficient under test. Generate first  
A list of essential features.
```{r, echo=TRUE, results='markup'}
coeffOfInterest = 2
res = fitLogNormal(obj = lungTrim, mod = mod, useCSSoffset = FALSE,
B = 10, coef = coeffOfInterest)
adjustedPvalues = p.adjust(res$p, method = "fdr")
foldChange = abs(res$fit$coef[, coeffOfInterest])
sigList = which(adjustedPvalues <= 0.05)
sigList = sigList[order(foldChange[sigList])]
head(taxa[sigList])
```

### Presence-absence testing
Implemented Existence-The absentee test hypothesis has given odds the traits that exist are higher/lower in one group of people than in another. I would like to test if the difference in the  observed ratios is significant. I'm using Fischer's accurate test to create  2x2 contingency table and calculate p-value, odds ratio, confidence twenty one interval. fitPA calculates the presence-absence of each organism and returns a table containing p-values, odds ratios, and confidence intervals. This function accepts one of the MRexperiments object or matrix. When MRfulltable sends the result from fitZig, it also includes the result from fit PA.
```{r, echo=TRUE, results='markup'}
classes = pData(mouseData)$diet
res = fitPA(mouseData[1:5, ], cl = classes)
head(res)
```

###  Discovery odds ratio testing
The hypothesis of the implemented detection test is that the  observed percentages are counted. One characteristic of all censuses is equivalent across groups. Created using Fisher's exact test Create a 2x2 contingency table and calculate the p-value, odds ratio, and confidence interval. fitDO Calculates the percentage of  each organism's count and returns a table of pvalues, odd`s 
Indicators and confidence intervals. This function can be an MRexperiment object or matrix.
```{r, echo=TRUE, results='markup'}
classes = pData(mouseData)$diet
res = fitDO(mouseData[1:100, ], cl = classes, norm = FALSE, log = FALSE)
head(res)
```

### Feature correlations
Implemented "correlation Test" and "correct Indicators" to test the frequency response or sample correlation in pairs. Correlation test function calculates basic Pearson, Spearman, and Kendal correlation statistics for inputs and rows report the relevant pvalue. Correlation is also calculated using a vector of length ncol (obj) Each row with a related vector.
```{r, echo=TRUE, results='markup'}
cors = correlationTest(mouseData[55:60, ], norm = FALSE, log = FALSE)
head(cors)
```

###  Unique OTUs or features
To find the missing features  from any number of classes, the uniqueFeatures function. A table of feature IDs, number of positive features, and reads for each group threshold The number of positive samples or  required readings is optional.
```{r, echo=TRUE, results='markup'}
cl = pData(mouseData)[["diet"]]
uniqueFeatures(mouseData, cl, nsamples = 10, nreads = 100)
```

## Aggregating counts
Normalization  at the OTU level is recommended. However, there is an aggregation function A count matrix  based on a particular user-defined level (whether normalized or not). Call aggregateByTaxonomy or aggTax using the featureData information of the MRexperiment object. Declaration of MRexperiment object and specific featureData column name (ie "genus"). Use the aggfun function (default colSums) to aggregate the counts to the desired level. Possible fun 
Alternatives are colMeans and colMedians.
```{r, echo=TRUE, results='markup'}
obj = aggTax(mouseData, lvl = "phylum", out = "matrix")
head(obj[1:5, 1:5])
```
In addition, sample aggregation can be performed using the phenoData information in the MRexperiment object. If you call aggregateBySample or aggsamp on an MRexperiment object and declare a specific phenoData column name (that is, "diet"), the count will be aggregated using aggfun. Function (default rowMeans). Possible aggfun alternatives are rowSums and rowMedians.
```{r, echo=TRUE, results='markup'}
obj = aggSamp(mouseData, fct = "mouseID", out = "matrix")
head(obj[1:5, 1:5])
```
The AggregateByTaxonomy, aggregateBySample, and aggTax aggSamp functions are flexible enough to contain either 1) a matrix containing a vector of labels, or 2) an MRexperiment object.The name of the label's vector  or featureData column. This function is a matrix or MRexperiment object.

## Visualization of features
To aid in the visualization and analysis of datasets, metagenomeSeq has multiple plotting capabilities that provide insights into the overall structure of the dataset and its unique individual characteristics. A The view feature allows you to view the first interactive exploration of your data. We provide various graphs, including heatmaps, to give you a complete picture of your dataset. Number of functions: plotMRheatmap, basic function correlation structure: plotCorr, PCA / MDS Sample or feature coordinates: plotOrd, dilution effect: plotRare and contingency Table-style graph: plotBubble.

### Interactive Display
Recent advances in the InteractiveDisplay package call the display function. The MRexperiment object opens a browser and explores the data through multiple interactive visualizations. For more detailed interactive visualizations, Shinyphyloseq package.

### Structural overview
Many studies begin by comparing the frequency composition of the entire specimen or trait phenotype. The first step in data analysis is often a heatmap, correlation or co-occurrence plot, or something similar. Other data exploration methods. The following features are implemented: 
Overview of the first steps of the data:

1. plotMRheatmap - heatmap of abundance estimates
2. plotCorr - heatmap of pairwise correlations
3. plotOrd - PCA/CMDS components
4. plotRare - rarefaction effect
5. plotBubble - contingency table style plot 

```{r, echo=TRUE, results='markup'}
trials = pData(mouseData)$diet
heatmapColColors = brewer.pal(12, "Set3")[as.integer(factor(trials))]
heatmapCols = colorRampPalette(brewer.pal(9, "RdBu"))(50)
plotMRheatmap(obj = mouseData, n = 200, cexRow = 0.4, cexCol = 0.4,
trace = "none", col = heatmapCols, ColSideColors = heatmapColColors)
# plotCorr
plotCorr(obj = mouseData, n = 200, cexRow = 0.25, cexCol = 0.25,
trace = "none", dendrogram = "none", col = heatmapCols)
```
Below is an example of plotting CMDS plots of the data and the rarefaction effect at the
OTU level. None of the data is removed
```{r, echo=TRUE, results='markup'}
cl = factor(pData(mouseData)$diet)
# plotOrd - can load vegan and set distfun = vegdist and
# use dist.method='bray'
plotOrd(mouseData, tran = TRUE, usePCA = FALSE, useDist = TRUE,
bg = cl, pch = 21)
# plotRare
res = plotRare(mouseData, cl = cl, pch = 21, bg = cl)
# Linear fits for plotRare / legend
tmp = lapply(levels(cl), function(lv) lm(res[, "ident"] ~ res[,
"libSize"] - 1, subset = cl == lv))
for (i in 1:length(levels(cl))) {
abline(tmp[[i]], col = i)
}
legend("topleft", c("Diet 1", "Diet 2"), text.col = c(1, 2),
box.col = NA)
```

### Feature specific

Highly similar and clustered reads represent functional or classification units. However,  reads from the same organism can be clustered into multiple OTUs. After the difference abundance analysis. It is important to see the difference in abundance. How to separate false the positive point is to make sure that the trait is actually abundant (enough positive sample) other the method is to record a wealth of features that are also annotated.

1. plotOTU - abundances of a particular feature by group 
2. plotGenus - abundances for several features similarly annotated by group 
3. plotFeature - abundances of a particular feature by group (similar to plotOTU

```{r, echo=TRUE, results='markup'}
head(MRtable(fit, coef = 2, taxa = 1:length(fData(lungTrim)$taxa)))
patients = sapply(strsplit(rownames(pData(lungTrim)), split = "_"),
function(i) {
i[3]
})
pData(lungTrim)$patients = patients
classIndex = list(smoker = which(pData(lungTrim)$SmokingStatus ==
"Smoker"))
classIndex$nonsmoker = which(pData(lungTrim)$SmokingStatus ==
"NonSmoker")
otu = 779
plotOTU(lungTrim, otu = otu, classIndex, main = "Neisseria meningitidis")
x = fData(lungTrim)$taxa[otu]
otulist = grep(x, fData(lungTrim)$taxa)
plotGenus(lungTrim, otulist, classIndex, labs = FALSE, main = "Neisseria meningitidis")
lablist <- c("S", "NS")
axis(1, at = seq(1, 6, by = 1), labels = rep(lablist, times = 3))
classIndex = list(Western = which(pData(mouseData)$diet == "Western"))
classIndex$BK = which(pData(mouseData)$diet == "BK")
otuIndex = 8770
dates = pData(mouseData)$date
plotFeature(mouseData, norm = FALSE, log = FALSE, otuIndex, classIndex,
col = dates, sortby = dates, ylab = "Raw reads")
```

## Summary
metagenomeSeq is specifically designed for sparse, high-throughput sequence experiments. Handles analysis of frequency differences in marker gene survey data. That wrap, Designed for marker gene collection datasets, but may be suitable for other sparse datasets. A zero-expansion Gaussian mixed model can be applied. If you  use  statistical methods, please cite our paper. If you have used manuals / software before Manual / software!
### Citing metagenomeSeq
```{r, echo=TRUE, results='markup'}
citation("metagenomeSeq")
```

## References

[1] Emily S Charlson, Kyle Bittinger, Andrew R Haas, Ayannah S Fitzgerald, Ian Frank, Anjana
Yadav, Frederic D Bushman, and Ronald G Collman. Topographical continuity of bacterial
populations in the healthy human respiratory tract. American Journal of Respiratory and
Critical Care Medicine, 184, 2011.

[2] Peter J Turnbaugh, Vanessa K Ridaura, Jeremiah J Faith, Federico E Rey, Rob Knight, and
Jeffrey I Gordon. The effect of diet on the human gut microbiome: a metagenomic analysis
in humanized gnotobiotic mice. Science translational medicine, 1(6):6ra14, 2009.

[3] Consortium HMP. A framework for human microbiome research. Nature, 486(7402), 2012.

[4] Gordon K Smyth. Limma: linear models for microarray data. Number October. Springer,
2005.

[5] A P Dempster, N M Laird, and D B Rubin. Maximum likelihood from incomplete data via
the em algorithm. Journal of the Royal Statistical Society Series B Methodological, 39(1):1â€“
38, 1977.